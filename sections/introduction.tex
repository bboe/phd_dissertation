\chapter{Introduction}
A recent study by code.org suggests that by 2020 there will be a one million
person gap in the United States between the number of computer science jobs
available and the number of people available to fill these jobs. Despite the
increase in enrollment in computer science undergraduate programs since 2008,
it is projected that the university system will not produce enough graduates
with computer science or related degrees to meet the demand.

This is a twofold problem. First, there is a depressing lack of computational
thinking related curriculum in primary and middle school. While many high
schools offer computer science courses, having just under 30,000 students
nationally take the AP Computer Science exam indicates a severe need for K--12
computational thinking curriculum reform. Second, the University system already
cannot handle the number of students applying to computer science programs,
thus turning away a significant number of people from an area they are severely
needed.

In this dissertation I describe methods that have a positive impact on solving
both the challenge to get more students interested in computer science, and the
challenge to support growth in the number of students of computer science in
Universities.

\section{Motivation and Background}
In order to meet demand, computer science departments need to scale up to the
largest enrollment size they can support without affecting the quality of
education provided. Past research has shown that automated feedback systems
both increase grading efficiency and reduce the time to feedback. Such systems
are ideal for supporting larger course enrollment while increasing the
percentage of students who complete the course. However, in spite of these
benefits, there is negligible adoption of existing systems throughout computer
science departments. Why is that? In attempt to help answer this question, my
research analyzes the impact of running an automated feedback system over a
one-year period in order to study student submission behaviors. I hope to show
that there is value added to university computer science departments by
incorporating these systems in the educational process and thus encourage
widespread adoption of automated feedback systems resulting in the increased
graduation of computer science students.

\section{Thesis Statement}
The increase in popularity of Computer Science has resulted in large demand for
Computer Science instruction, from primary school through college. These two
ends of the spectrum, however, are in far different places in their
development, with very little curriculum existing for primary schools and very
mature instruction available for college. Assessment automation can greatly
enhance both efforts, albeit in different ways. At the primary school level,
assessment automation through static analysis of student work can provide
insight to student comprehension thus permitting rapid curriculum changes, but
this insight is limited by the structure of assignments and the amount of data
collected. At the collegiate level, automated assessment can provide students
with insight to their success on an assignment allowing them to iteratively
achieve mastery, however, the timeliness and quantity of feedback may inhibit
students' mastery of important secondary processes.

\section{Dissertation Overview}
This dissertation is structured as follows. In chapter~\ref{chap:hairball} we
describe our use of static analysis to assist with the post assessment of a
Scratch-based summer camp. In chapter~\ref{chap:curriculum} we further look at
static analysis of Scratch-based assignments in the context of near-real-time
curriculum development for primary school education. In
chapter~\ref{chap:feedback} we look at submission behaviors of college-level
Computer Science students in the presence of a real-time feedback and
submission system. Finally, in chapter~\ref{chap:conclusion} we conclude.
