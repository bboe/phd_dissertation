\section{Introduction}
The growing demand for computer science education is resulting in a shift
toward larger class sizes. In order to accommodate these larger classes, many
computer science instructors have begun to utilize automated assessment
technology where their students submit assignments electronically, and a
significant portion of the assessment is performed by pre-written test cases
and static analysis. Furthermore, a subset of these automated assessment
systems provide students with real-time feedback and unlimited submission
attempts up to the deadline making it possible for students to iteratively
achieve mastery on their assignments. While these feedback and assessment
systems support scaling class sizes with a minimal increase in human resources,
little is known about the impact of such systems on student learning.

We created and deployed a real-time feedback and assessment system for the
purposes of supporting scale in University of California, Santa Barbara (UCSB)
computer science lower division courses. From others' prior work, and our own
previous experience with real-time feedback and assessment systems, we knew
that the use of our new system would significantly reduce assignment assessment
time, permitting instructors and teaching assistants more time to work
one-on-one with students in need of additional help. Our system was tested with
289 consent giving students in a total of seven instances of two UCSB computer
science courses from Winter Quarter 2013 through Spring Quarter 2014.

Anecdotal evidence suggested that while the system permitted students to
achieve success on assignments, the students were observed to rely on the
system rather than develop their own testing and debugging skills --- skills
they were previous forced to develop in order to succeed in the absence of
real-time feedback. We hypothesized that students who are able receive
significant feedback in any given period of time will take advantage of the
system to the detriment of their testing and debugging skill
development. Although our system does not evaluate these skills, it measures
the effect that changes in feedback timing, referred to as feedback delay, have
on student assignment progress. Therefore, we sought to measure this effect on
students in attempt to discourage reliance upon the real-time feedback and
assessment system, and thus support students' continued self-development of
testing and debugging skills.

In this study we present the results obtained by an analysis of 20,777
submissions made by 289 consent giving students as previously described. We
provide a general overview of student submission behavior in the presence of a
real-time feedback and assessment system, and provide an analysis of the
feedback delay's effect on student submission behavior.

The remainder of this study is organized as follows. We provide a brief summary
of related work in Section~\localref{sec:relatedwork}. In
Section~\localref{sec:methodology} we describe the methodology of our study. We
then present our results in Section~\localref{sec:results}, and finally,
conclude in Section~\localref{sec:conclusion}.
